{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edf52b2-692f-4739-9101-0e0d8d0402de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:20:25.421810Z",
     "iopub.status.busy": "2025-11-14T14:20:25.421640Z",
     "iopub.status.idle": "2025-11-14T14:21:49.461563Z",
     "shell.execute_reply": "2025-11-14T14:21:49.460863Z",
     "shell.execute_reply.started": "2025-11-14T14:20:25.421793Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/requires/requirements.txt (line 2)) (2.6.0+cu124)\n",
      "Collecting transformers>=4.55.0 (from -r /kaggle/input/requires/requirements.txt (line 3))\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/requires/requirements.txt (line 6)) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/requires/requirements.txt (line 7)) (1.2.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/requires/requirements.txt (line 10)) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/requires/requirements.txt (line 13)) (0.36.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2)) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.55.0->-r /kaggle/input/requires/requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.55.0->-r /kaggle/input/requires/requirements.txt (line 3)) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.55.0->-r /kaggle/input/requires/requirements.txt (line 3)) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.55.0->-r /kaggle/input/requires/requirements.txt (line 3)) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.55.0->-r /kaggle/input/requires/requirements.txt (line 3))\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.55.0->-r /kaggle/input/requires/requirements.txt (line 3)) (0.5.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->-r /kaggle/input/requires/requirements.txt (line 6)) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->-r /kaggle/input/requires/requirements.txt (line 6)) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->-r /kaggle/input/requires/requirements.txt (line 6)) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->-r /kaggle/input/requires/requirements.txt (line 6)) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->-r /kaggle/input/requires/requirements.txt (line 6)) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->-r /kaggle/input/requires/requirements.txt (line 6)) (2.4.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->-r /kaggle/input/requires/requirements.txt (line 7)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->-r /kaggle/input/requires/requirements.txt (line 7)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->-r /kaggle/input/requires/requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.34.0->-r /kaggle/input/requires/requirements.txt (line 13)) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r /kaggle/input/requires/requirements.txt (line 2)) (3.0.3)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->-r /kaggle/input/requires/requirements.txt (line 6)) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->-r /kaggle/input/requires/requirements.txt (line 6)) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->-r /kaggle/input/requires/requirements.txt (line 6)) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.0->-r /kaggle/input/requires/requirements.txt (line 6)) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.0->-r /kaggle/input/requires/requirements.txt (line 6)) (2024.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.55.0->-r /kaggle/input/requires/requirements.txt (line 3)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.55.0->-r /kaggle/input/requires/requirements.txt (line 3)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.55.0->-r /kaggle/input/requires/requirements.txt (line 3)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.55.0->-r /kaggle/input/requires/requirements.txt (line 3)) (2025.10.5)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.0->-r /kaggle/input/requires/requirements.txt (line 6)) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.2\n",
      "    Uninstalling tokenizers-0.21.2:\n",
      "      Successfully uninstalled tokenizers-0.21.2\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.53.3\n",
      "    Uninstalling transformers-4.53.3:\n",
      "      Successfully uninstalled transformers-4.53.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tokenizers-0.22.1 transformers-4.57.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r \"/kaggle/input/requires/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc56187-ec9b-4e0a-8aff-767019f2477f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:21:49.465372Z",
     "iopub.status.busy": "2025-11-14T14:21:49.465127Z",
     "iopub.status.idle": "2025-11-14T14:21:50.012274Z",
     "shell.execute_reply": "2025-11-14T14:21:50.011698Z",
     "shell.execute_reply.started": "2025-11-14T14:21:49.465336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "token=\"\"\n",
    "from huggingface_hub import login\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0535f094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:22:22.662980Z",
     "iopub.status.busy": "2025-11-14T14:22:22.662661Z",
     "iopub.status.idle": "2025-11-14T14:23:22.050910Z",
     "shell.execute_reply": "2025-11-14T14:23:22.049738Z",
     "shell.execute_reply.started": "2025-11-14T14:22:22.662956Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477aad5ce3e44374ba7237d74627550e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8a29a04d4a4e269c6badaa01af08d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8aa6dd5ddf4cd8a2fed56f67db8ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c62359ee4804fd9849ee2e367fe1d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model (this may take a few minutes)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8222f7310e400b827d2f422a6120b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-14 14:22:33.965349: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763130154.159823      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763130154.212284      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3308c5109da41c096972c14bd9799a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36332529efa4f738a06afebfa005d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: /kaggle/input/bigmodel/HC3_en_test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing KL for HC3_en_test.json:   0%|          | 11/6526 [00:13<2:14:39,  1.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48/2569601465.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtext_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Computing KL for {file_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_kl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mkls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# limit for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_48/2569601465.py\u001b[0m in \u001b[0;36mget_kl\u001b[0;34m(model, input_texts)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"batchmean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         )\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mkls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl_first\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkl_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mkls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def last_token_pool(last_hidden_states, attention_mask):\n",
    "    left_padding=(attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths=attention_mask.sum(dim=1) - 1\n",
    "        batch_size=last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_length=512\n",
    "\n",
    "\n",
    "pretrained_model_name_or_path=\"Qwen/Qwen2-1.5B-Instruct\"\n",
    "which_embedding=\"Qwen2-1.5B-Instruct_embedding\"\n",
    "\n",
    "save_dir=f\"/kaggle/working/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer=AutoTokenizer.from_pretrained(pretrained_model_name_or_path, trust_remote_code=True)\n",
    "tokenizer.pad_token=tokenizer.eos_token\n",
    "\n",
    "print(\"Loading model (this may take a few minutes)...\")\n",
    "model=AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_kl(model, input_texts):\n",
    "    \n",
    "    batch_dict=tokenizer(input_texts, max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs=model(**batch_dict, output_hidden_states=True)\n",
    "\n",
    "        \n",
    "        last_logits=model.lm_head(outputs.hidden_states[-1]).squeeze()\n",
    "        first_logits=model.lm_head(outputs.hidden_states[0]).squeeze()\n",
    "\n",
    "    kls=[]\n",
    "    for i in range(1, len(outputs.hidden_states) - 1):\n",
    "        with torch.no_grad():\n",
    "            middle_logits=model.lm_head(outputs.hidden_states[i]).squeeze()\n",
    "        kl_first=F.kl_div(\n",
    "            F.log_softmax(middle_logits, dim=-1),\n",
    "            F.softmax(first_logits, dim=-1),\n",
    "            reduction=\"batchmean\",\n",
    "        )\n",
    "        kl_last=F.kl_div(\n",
    "            F.log_softmax(middle_logits, dim=-1),\n",
    "            F.softmax(last_logits, dim=-1),\n",
    "            reduction=\"batchmean\",\n",
    "        )\n",
    "        kls.append((kl_first + kl_last).item())\n",
    "    return kls\n",
    "\n",
    "data_dir=\"/kaggle/input/bigmodel\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(data_dir):  \n",
    "    for file_name in files:\n",
    "        if not file_name.endswith(\".json\"):\n",
    "            continue  \n",
    "\n",
    "        file_path=os.path.join(root, file_name)\n",
    "        save_path=os.path.join(save_dir, file_name.split('.')[0] + '.pkl')\n",
    "\n",
    "        if os.path.exists(save_path):\n",
    "            print(f\"Already exists: {save_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing: {file_path}\")\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data=json.load(f)\n",
    "\n",
    "        kls=[]\n",
    "        for text_info in tqdm(data, desc=f\"Computing KL for {file_name}\"):\n",
    "            text=text_info[\"text\"]\n",
    "            kl=get_kl(model, [text])\n",
    "            kls.append(kl)\n",
    "            if len(kls) >= 3000:  \n",
    "                break\n",
    "\n",
    "        print(f\"Saving: {save_path}\")\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(kls, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8cfc91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:23:26.065663Z",
     "iopub.status.busy": "2025-11-14T14:23:26.065107Z",
     "iopub.status.idle": "2025-11-14T14:34:49.546654Z",
     "shell.execute_reply": "2025-11-14T14:34:49.545864Z",
     "shell.execute_reply.started": "2025-11-14T14:23:26.065635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5febbb0f6441d1abf71fecd6c0be0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dbd627bee146a18ed1093fb5e7b9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenization_qwen.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Alibaba-NLP/gte-Qwen2-1.5B-instruct:\n",
      "- tokenization_qwen.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a48694252d412296f0666bb1515ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842fcd6a8e9644c292c494f205329ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682c2b31824f4ba1aff973de96cac237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63252f9c68a46d286708da525433a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f5f3716de14c8f97e4579c2beb5444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/370 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model (this may take a few minutes on first run)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3de562cc684a059323d3b13ae52f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/901 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4628fef25a3247acbecc33c16e892771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_qwen.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Alibaba-NLP/gte-Qwen2-1.5B-instruct:\n",
      "- modeling_qwen.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef842c2416641de96db336005295e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbb3d5f2ece40ccbb66cb3abe864f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c274372995c544f8b395d5347a2754ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e0f0b7954b447caf85a532b458617e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e68acc9840640979ff901d8bd9272f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: HC3_en_test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding HC3_en_test.json:  46%|████▌     | 2999/6526 [10:46<12:40,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: torch.Size([3000, 44544])\n",
      "Saved: /kaggle/working/HC3_en_test.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def last_token_pool(last_hidden_states, attention_mask):\n",
    "    left_padding=(attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths=attention_mask.sum(dim=1) - 1\n",
    "        batch_size=last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_length=512\n",
    "\n",
    "\n",
    "pretrained_model_name_or_path=\"Alibaba-NLP/gte-Qwen2-1.5B-instruct\"\n",
    "which_embedding=\"gte-qwen1.5-1.5B_all_embedding\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer=AutoTokenizer.from_pretrained(pretrained_model_name_or_path, trust_remote_code=True)\n",
    "tokenizer.pad_token=tokenizer.eos_token\n",
    "\n",
    "print(\"Loading model (this may take a few minutes on first run)...\")\n",
    "model=AutoModel.from_pretrained(pretrained_model_name_or_path, trust_remote_code=True, device_map=\"auto\")\n",
    "model.eval()\n",
    "def get_all_embedding(model, input_texts):\n",
    "    batch_dict=tokenizer(\n",
    "        input_texts,\n",
    "        max_length=max_length,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs=model(\n",
    "            **batch_dict,\n",
    "            output_hidden_states=True,\n",
    "            use_cache=False   \n",
    "        )\n",
    "\n",
    "    all_embed=[\n",
    "        last_token_pool(outputs.hidden_states[i], batch_dict['attention_mask'])\n",
    "        for i in range(len(outputs.hidden_states))\n",
    "    ]\n",
    "    all_embed=torch.cat(all_embed, dim=1).cpu()\n",
    "    return all_embed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_dir=\"/kaggle/input/bigmodel\"\n",
    "save_dir=f\"/kaggle/working/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file_name in os.listdir(data_dir):\n",
    "    save_path=os.path.join(save_dir, file_name.split('.')[0] + '.pt')\n",
    "    if os.path.exists(save_path):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing: {file_name}\")\n",
    "    with open(os.path.join(data_dir, file_name), \"r\") as f:\n",
    "        data=json.load(f)\n",
    "\n",
    "    embeddings=[]\n",
    "    for text_info in tqdm(data, desc=f\"Embedding {file_name}\"):\n",
    "        text=text_info[\"text\"]\n",
    "        embedding=get_all_embedding(model, [text])\n",
    "        embeddings.append(embedding)\n",
    "        if len(embeddings) >= 3000:  \n",
    "            break\n",
    "\n",
    "    embeddings=torch.cat(embeddings, dim=0)\n",
    "    print(\"Embedding shape:\", embeddings.shape)\n",
    "    torch.save(embeddings, save_path)\n",
    "    print(\"Saved:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e7977",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:52:06.378642Z",
     "iopub.status.busy": "2025-11-14T14:52:06.378055Z",
     "iopub.status.idle": "2025-11-14T14:52:07.573757Z",
     "shell.execute_reply": "2025-11-14T14:52:07.572963Z",
     "shell.execute_reply.started": "2025-11-14T14:52:06.378617Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferring layer dims from training file…\n",
      "Loading embedding: /kaggle/input/newnewmodels\\HC3_en_test.pt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/newnewmodels\\\\HC3_en_test.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 149\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# ---- GET PER-LAYER DIM ----\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInferring layer dims from training file…\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 149\u001b[0m sample_embed\u001b[38;5;241m=\u001b[39m\u001b[43mload_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m sample_kl\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(load_kl(train_file))\n\u001b[0;32m    152\u001b[0m per_layer_dim, total_states\u001b[38;5;241m=\u001b[39minfer_per_layer_dim(sample_embed, sample_kl[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[1], line 44\u001b[0m, in \u001b[0;36mload_embedding\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     42\u001b[0m path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(EMB_BASE, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading embedding:\u001b[39m\u001b[38;5;124m\"\u001b[39m, path)\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\2maju\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1425\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1423\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1425\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1427\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\2maju\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:751\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 751\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\2maju\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:732\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 732\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/newnewmodels\\\\HC3_en_test.pt'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, f1_score,\n",
    "    precision_score, recall_score, confusion_matrix\n",
    ")\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "EMB_BASE   =\"/kaggle/input/newnewmodels\"\n",
    "KL_BASE    =\"/kaggle/input/newnewpickle\"\n",
    "LABEL_BASE =\"/kaggle/input/newlabels\"\n",
    "\n",
    "train_file=\"HC3_en_test\"\n",
    "valid_file=\"gpt4-Xsum-gpt3\"\n",
    "test_files=[\"gpt4-pub-gpt3\", \"gpt4-writing-gpt3\"]\n",
    "\n",
    "which_layer=\"max_kl\"\n",
    "learning_rate=1e-3\n",
    "batch_size=16\n",
    "num_epochs=10\n",
    "hidden_sizes=[1024, 512]\n",
    "dropout_prob=0.2\n",
    "\n",
    "best_model_path=\"best_binary_classifier.pt\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_embedding(name):\n",
    "    path=os.path.join(EMB_BASE, f\"{name}.pt\")\n",
    "    print(\"Loading embedding:\", path)\n",
    "    return torch.load(path, map_location=\"cpu\")\n",
    "\n",
    "def load_labels(name):\n",
    "    path=os.path.join(LABEL_BASE, f\"{name}.pt\")\n",
    "    print(\"Loading labels:\", path)\n",
    "    labels=torch.load(path, map_location=\"cpu\").long()\n",
    "\n",
    "    if labels.min() < 0 or labels.max() > 1:\n",
    "        raise ValueError(f\"[ERROR] Labels for {name} contain non-binary values.\")\n",
    "    return labels\n",
    "\n",
    "def load_kl(name):\n",
    "    path=os.path.join(KL_BASE, f\"{name}.pkl\")\n",
    "    print(\"Loading KL:\", path)\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def infer_per_layer_dim(embed, sample_kl):\n",
    "    L=len(sample_kl)\n",
    "    total_states=L + 2\n",
    "    D=embed.shape[1]\n",
    "\n",
    "    if D % total_states != 0:\n",
    "        raise ValueError(f\"Dimension mismatch: D={D} states={total_states}\")\n",
    "\n",
    "    return D // total_states, total_states\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def select_max_kl(embed, kl, per_layer):\n",
    "    idx=kl.argmax(axis=1)\n",
    "    selected=[]\n",
    "\n",
    "    for i, layer in enumerate(idx):\n",
    "        start=(layer + 1) * per_layer\n",
    "        end  =(layer + 2) * per_layer\n",
    "        selected.append(embed[i, start:end])\n",
    "\n",
    "    return torch.stack(selected, dim=0)\n",
    "\n",
    "def select_layer_embeddings(embed, kl, per_layer, mode):\n",
    "    if mode == \"max_kl\":\n",
    "        return select_max_kl(embed, kl, per_layer)\n",
    "    elif mode == \"last_layer\":\n",
    "        return embed[:, -per_layer:]\n",
    "    else:\n",
    "        raise ValueError(\"Unknown which_layer:\", mode)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, dropout_prob):\n",
    "        super().__init__()\n",
    "\n",
    "        layers=[]\n",
    "        prev=input_size\n",
    "\n",
    "        for h in hidden_sizes:\n",
    "            layers += [\n",
    "                nn.Dropout(dropout_prob),\n",
    "                nn.Linear(prev, h),\n",
    "                nn.ReLU(),\n",
    "            ]\n",
    "            prev=h\n",
    "\n",
    "        self.dense=nn.Sequential(*layers)\n",
    "        self.classifier=nn.Linear(prev, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.dense(x))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepare_dataset(name, max_items=None):\n",
    "    emb=load_embedding(name)\n",
    "    labels=load_labels(name)\n",
    "    kl=np.array(load_kl(name))\n",
    "\n",
    "    min_size=min(len(emb), len(labels), len(kl))\n",
    "    if max_items is not None:\n",
    "        min_size=min(min_size, max_items)\n",
    "\n",
    "    emb=emb[:min_size]\n",
    "    labels=labels[:min_size]\n",
    "    kl=kl[:min_size]\n",
    "\n",
    "    emb_sel=select_layer_embeddings(\n",
    "        embed=emb,\n",
    "        kl=kl,\n",
    "        per_layer=per_layer_dim,\n",
    "        mode=which_layer,\n",
    "    )\n",
    "\n",
    "    return emb_sel.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nInferring layer dims from training file…\")\n",
    "sample_embed=load_embedding(train_file)\n",
    "sample_kl=np.array(load_kl(train_file))\n",
    "\n",
    "per_layer_dim, total_states=infer_per_layer_dim(sample_embed, sample_kl[0])\n",
    "print(\"Per-layer hidden dim:\", per_layer_dim)\n",
    "print(\"Total states:\", total_states)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nPreparing datasets...\")\n",
    "train_embeddings, train_labels=prepare_dataset(train_file, max_items=3000)\n",
    "valid_embeddings, valid_labels=prepare_dataset(valid_file, max_items=3000)\n",
    "\n",
    "test_embeddings=[]\n",
    "test_labels=[]\n",
    "for t in test_files:\n",
    "    try:\n",
    "        e, l=prepare_dataset(t, max_items=3000)\n",
    "        test_embeddings.append(e)\n",
    "        test_labels.append(l)\n",
    "    except Exception as ex:\n",
    "        print(\"Skipping:\", t, \"| Reason:\", ex)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, emb, labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits=model(emb)\n",
    "        probs=torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
    "        preds=(probs >= 0.5).astype(int)\n",
    "        labels_np=labels.cpu().numpy()\n",
    "\n",
    "        return {\n",
    "            \"acc\": accuracy_score(labels_np, preds),\n",
    "            \"auroc\": roc_auc_score(labels_np, probs),\n",
    "            \"precision\": precision_score(labels_np, preds, zero_division=0),\n",
    "            \"recall\": recall_score(labels_np, preds, zero_division=0),\n",
    "            \"f1\": f1_score(labels_np, preds, zero_division=0),\n",
    "            \"confusion_matrix\": confusion_matrix(labels_np, preds).tolist(),\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    model=BinaryClassifier(\n",
    "        input_size=train_embeddings.shape[1],\n",
    "        hidden_sizes=hidden_sizes,\n",
    "        dropout_prob=dropout_prob\n",
    "    ).to(device)\n",
    "\n",
    "    opt=torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn=nn.CrossEntropyLoss()\n",
    "\n",
    "    best_acc=-1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        perm=torch.randperm(train_embeddings.shape[0])\n",
    "\n",
    "        total_loss=0\n",
    "\n",
    "        for i in range(0, len(perm), batch_size):\n",
    "            idx=perm[i:i+batch_size]\n",
    "            emb=train_embeddings[idx]\n",
    "            lab=train_labels[idx]\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss=loss_fn(model(emb), lab)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        val=evaluate(model, valid_embeddings, valid_labels)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:02d} | loss={total_loss:.4f} | \"\n",
    "            f\"acc={val['acc']:.4f} | f1={val['f1']:.4f} | \"\n",
    "            f\"precision={val['precision']:.4f} | recall={val['recall']:.4f} | \"\n",
    "            f\"auroc={val['auroc']:.4f}\"\n",
    "        )\n",
    "\n",
    "        if val[\"acc\"] > best_acc:\n",
    "            best_acc=val[\"acc\"]\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(\" Saved BEST model.\")\n",
    "\n",
    "    print(\"\\nTraining complete. Best validation acc:\", best_acc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_model()\n",
    "print(\"\\nDONE.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7c9b4-7c71-41a6-98d6-08e1aeb08c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:56:07.413691Z",
     "iopub.status.busy": "2025-11-14T14:56:07.413095Z",
     "iopub.status.idle": "2025-11-14T14:56:07.420993Z",
     "shell.execute_reply": "2025-11-14T14:56:07.420415Z",
     "shell.execute_reply.started": "2025-11-14T14:56:07.413670Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    confusion_matrix, roc_auc_score, f1_score\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train=train_embeddings.cpu().numpy()\n",
    "y_train=train_labels.cpu().numpy()\n",
    "\n",
    "X_valid=valid_embeddings.cpu().numpy()\n",
    "y_valid=valid_labels.cpu().numpy()\n",
    "\n",
    "test_sets_np=[]\n",
    "for e, l in zip(test_embeddings, test_labels):\n",
    "    test_sets_np.append((e.cpu().numpy(), l.cpu().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da717b2e-38ce-48c6-b22c-283bc96e544f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:56:07.645516Z",
     "iopub.status.busy": "2025-11-14T14:56:07.645257Z",
     "iopub.status.idle": "2025-11-14T14:56:07.650372Z",
     "shell.execute_reply": "2025-11-14T14:56:07.649595Z",
     "shell.execute_reply.started": "2025-11-14T14:56:07.645498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classifier(model, X, y):\n",
    "    \n",
    "    probs=model.predict_proba(X)[:, 1]\n",
    "    preds=(probs >= 0.5).astype(int)\n",
    "\n",
    "    return {\n",
    "        \"acc\": accuracy_score(y, preds),\n",
    "        \"auroc\": roc_auc_score(y, probs),\n",
    "        \"precision\": precision_score(y, preds, zero_division=0),\n",
    "        \"recall\": recall_score(y, preds, zero_division=0),\n",
    "        \"f1\": f1_score(y, preds, zero_division=0),\n",
    "        \"confusion_matrix\": confusion_matrix(y, preds).tolist(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3995b3-84b1-4fbc-b432-9ad8b12fec8b",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89d9622-4f93-4d72-b507-f4e7b26753e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:56:09.544956Z",
     "iopub.status.busy": "2025-11-14T14:56:09.544144Z",
     "iopub.status.idle": "2025-11-14T14:56:11.122592Z",
     "shell.execute_reply": "2025-11-14T14:56:11.121814Z",
     "shell.execute_reply.started": "2025-11-14T14:56:09.544930Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "Training Random Forest\n",
      "======================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Random Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m======================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m rf\u001b[38;5;241m=\u001b[39m\u001b[43mRandomForestClassifier\u001b[49m(\n\u001b[0;32m      6\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m,\n\u001b[0;32m      7\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m,\n\u001b[0;32m      8\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m     10\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✔ Random Forest trained!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n======================\")\n",
    "print(\"Training Random Forest\")\n",
    "print(\"======================\")\n",
    "\n",
    "rf=RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    max_depth=40,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print(\" Random Forest trained!\")\n",
    "\n",
    "print(\"\\n=== RF Validation ===\")\n",
    "rf_val=evaluate_classifier(rf, X_valid, y_valid)\n",
    "for k, v in rf_val.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "\n",
    "for (X, y), name in zip(test_sets_np, test_files):\n",
    "    print(f\"\\n=== RF Test: {name} ===\")\n",
    "    r=evaluate_classifier(rf, X, y)\n",
    "    for k, v in r.items():\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315bf7a0-f4f8-44ee-a0fa-056b7481e129",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:56:17.663180Z",
     "iopub.status.busy": "2025-11-14T14:56:17.662590Z",
     "iopub.status.idle": "2025-11-14T14:56:17.706294Z",
     "shell.execute_reply": "2025-11-14T14:56:17.705693Z",
     "shell.execute_reply.started": "2025-11-14T14:56:17.663157Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================\n",
      "Training SVM RBF\n",
      "================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining SVM RBF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m svm\u001b[38;5;241m=\u001b[39m\u001b[43mSVC\u001b[49m(\n\u001b[0;32m      6\u001b[0m     kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[0;32m      8\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,   \u001b[38;5;66;03m# MUST for predict_proba()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m svm\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✔ SVM trained!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n================\")\n",
    "print(\"Training SVM RBF\")\n",
    "print(\"================\")\n",
    "\n",
    "svm=SVC(\n",
    "    kernel=\"rbf\",\n",
    "    C=15,\n",
    "    gamma=\"scale\",\n",
    "    probability=True,   \n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "print(\" SVM trained!\")\n",
    "\n",
    "print(\"\\n=== SVM Validation ===\")\n",
    "svm_val=evaluate_classifier(svm, X_valid, y_valid)\n",
    "for k, v in svm_val.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "\n",
    "for (X, y), name in zip(test_sets_np, test_files):\n",
    "    print(f\"\\n=== SVM Test: {name} ===\")\n",
    "    r=evaluate_classifier(svm, X, y)\n",
    "    for k, v in r.items():\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8fafae-eceb-4c6f-b4af-4a73584e095b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T15:10:38.162192Z",
     "iopub.status.busy": "2025-11-14T15:10:38.161930Z",
     "iopub.status.idle": "2025-11-14T15:10:38.209308Z",
     "shell.execute_reply": "2025-11-14T15:10:38.208702Z",
     "shell.execute_reply.started": "2025-11-14T15:10:38.162171Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading best binary classifier...\n",
      "\n",
      "---- VALIDATION SET METRICS ----\n",
      "{'acc': 0.825503355704698, 'auroc': 0.8942389982433224, 'precision': 0.8702290076335878, 'recall': 0.7651006711409396, 'f1': 0.8142857142857143, 'confusion_matrix': [[132, 17], [35, 114]]}\n",
      "\n",
      "---- TEST SET METRICS ----\n",
      "{'acc': 0.5503355704697986, 'auroc': 0.573983153911986, 'precision': 0.6271186440677966, 'recall': 0.2483221476510067, 'f1': 0.3557692307692308, 'confusion_matrix': [[127, 22], [112, 37]]}\n",
      "{'acc': 0.77, 'auroc': 0.8619111111111112, 'precision': 0.8403361344537815, 'recall': 0.6666666666666666, 'f1': 0.7434944237918216, 'confusion_matrix': [[131, 19], [50, 100]]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nLoading best binary classifier...\")\n",
    "best_model=BinaryClassifier(\n",
    "    input_size=train_embeddings.shape[1],\n",
    "    hidden_sizes=hidden_sizes,\n",
    "    dropout_prob=dropout_prob\n",
    ").to(device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "best_model.eval()\n",
    "\n",
    "print(\"\\n---- VALIDATION SET METRICS ----\")\n",
    "val_metrics=evaluate(best_model, valid_embeddings, valid_labels)\n",
    "print(val_metrics)\n",
    "\n",
    "\n",
    "print(\"\\n---- TEST SET METRICS ----\")\n",
    "for emb, lab in zip(test_embeddings, test_labels):\n",
    "    metrics=evaluate(best_model, emb, lab)\n",
    "    print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f108a-f67c-4c70-8751-eeaabfeabd39",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8733804,
     "sourceId": 13727609,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8733825,
     "sourceId": 13727643,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8734993,
     "sourceId": 13729312,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8735102,
     "sourceId": 13729505,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8735218,
     "sourceId": 13729656,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8735353,
     "sourceId": 13729854,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8735479,
     "sourceId": 13730027,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8735534,
     "sourceId": 13730103,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8735561,
     "sourceId": 13730138,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8735655,
     "sourceId": 13730267,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8737648,
     "sourceId": 13733044,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8737819,
     "sourceId": 13733272,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8737863,
     "sourceId": 13733334,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
