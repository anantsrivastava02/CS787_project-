{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWi8Z5Z5Q7kE",
        "outputId": "923eb538-447f-4cdf-e6f8-a940c4d1cb04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 7050.32it/s]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "tqdm.pandas(dynamic_ncols=True)\n",
        "\n",
        "def text_entropy(text):\n",
        "    if not text or not isinstance(text, str):\n",
        "        return 0.0\n",
        "    freq = {}\n",
        "    for c in text:\n",
        "        freq[c] = freq.get(c, 0) + 1\n",
        "    total = len(text)\n",
        "    return -sum((count/total) * math.log2(count/total) for count in freq.values())\n",
        "\n",
        "df = pd.read_csv(\"/content/llama3.2_3b_results.csv\")\n",
        "df[\"entropy\"] = df[\"model_response\"].progress_apply(text_entropy)\n",
        "df.to_csv(\"/content/llama3.2_3b_results.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "MODEL_NAME = \"gpt2\"\n",
        "MAX_LENGTH = 256\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
        "model.eval()\n",
        "\n",
        "@torch.no_grad()\n",
        "def sequence_entropy(text, use_device):\n",
        "    if not text or not isinstance(text, str):\n",
        "        return 0.0\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=MAX_LENGTH)\n",
        "    inputs = {k: v.to(use_device) for k, v in inputs.items()}\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    seq_len = input_ids.size(1)\n",
        "    if seq_len <= 1:\n",
        "        return 0.0\n",
        "\n",
        "    entropies = []\n",
        "    for i in range(1, seq_len):\n",
        "        logits = model(input_ids[:, :i]).logits[:, -1, :]\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        entropy = -torch.sum(probs * torch.log2(probs + 1e-12), dim=-1)\n",
        "        entropies.append(float(entropy.cpu().item()))\n",
        "    return sum(entropies) / len(entropies)\n",
        "\n",
        "input_path = \"/content/result_1_texts1.csv\"\n",
        "output_path = input_path\n",
        "\n",
        "df = pd.read_csv(input_path)\n",
        "\n",
        "if \"entropy_new\" not in df.columns:\n",
        "    df[\"entropy_new\"] = pd.NA\n",
        "\n",
        "rows_to_process = df[df[\"entropy_new\"].isna()].index.tolist()\n",
        "\n",
        "for idx in tqdm(rows_to_process, dynamic_ncols=True):\n",
        "    text = df.at[idx, \"text\"]\n",
        "    try:\n",
        "        ent = sequence_entropy(text, device)\n",
        "    except Exception:\n",
        "        try:\n",
        "            torch.cuda.empty_cache()\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            model.to(\"cpu\")\n",
        "            ent = sequence_entropy(text, torch.device(\"cpu\"))\n",
        "            if device.type == \"cuda\":\n",
        "                model.to(device)\n",
        "        except Exception:\n",
        "            ent = float(\"nan\")\n",
        "    df.at[idx, \"entropy_new\"] = ent\n",
        "    df.to_csv(output_path, index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFsdHU6SUjNb",
        "outputId": "0cde4e1a-41c3-40d2-bd0f-ff1297c5a2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [06:47<00:00,  2.72s/it]\n"
          ]
        }
      ]
    }
  ]
}